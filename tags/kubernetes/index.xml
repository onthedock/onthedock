<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kubernetes on On The Dock</title>
    <link>https://onthedock.github.io/tags/kubernetes/index.xml</link>
    <description>Recent content in Kubernetes on On The Dock</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Handmade with &amp;#9829; by Xavi Aznar</copyright>
    <atom:link href="https://onthedock.github.io/tags/kubernetes/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Crear un cluster de un solo nodo</title>
      <link>https://onthedock.github.io/post/170702-crear-un-cluster-de-un-solo-nodo/</link>
      <pubDate>Sun, 02 Jul 2017 23:14:22 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170702-crear-un-cluster-de-un-solo-nodo/</guid>
      <description>&lt;p&gt;Para tener un clúster de desarrollo con la versatilidad de poder hacer y deshacer cambios (usando los &lt;em&gt;snapshots&lt;/em&gt; de una máquina virtual), lo más sencillo es disponer de un clúster de Kubernetes de un solo nodo.&lt;/p&gt;

&lt;p&gt;
Por defecto, el nodo master de un clúster de Kubernetes no ejecuta ningún tipo de carga de trabajo relacionada con los pods desplegados en el clúster, centrándose en las tareas de gestión de los &lt;em&gt;pods&lt;/em&gt; y del propio clúster.&lt;/p&gt;

&lt;p&gt;Para permitir que el nodo master pueda ejecutar &lt;em&gt;pods&lt;/em&gt;, debemos modificar las opciones por defecto de Kubernetes.&lt;/p&gt;

&lt;p&gt;En primer lugar, comprobamos que todos los pods del espacio de nombres de sistema han arrancado y se ejecutan correctamente:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get nodes --all-namespaces
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para que el nodo master admita el despliegue de &lt;em&gt;pods&lt;/em&gt;, modificamos mediante:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl taint nodes --all node-role.kubernetes.io/master-
node &amp;quot;k8s-snc&amp;quot; untainted
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Revisión de conceptos</title>
      <link>https://onthedock.github.io/post/170528-revision-de-conceptos/</link>
      <pubDate>Sun, 28 May 2017 07:59:31 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170528-revision-de-conceptos/</guid>
      <description>&lt;p&gt;Después de estabilizar el clúster, el siguiente paso es poner en marcha aplicaciones. Pero ¿qué es exactamente lo que hay que desplegar?: ¿&lt;em&gt;pods&lt;/em&gt;?, ¿&lt;em&gt;replication controllers&lt;/em&gt;?, ¿&lt;em&gt;deployments&lt;/em&gt;?&lt;/p&gt;

&lt;p&gt;Muchos artículos empiezan creando el fichero YAML para un &lt;em&gt;pod&lt;/em&gt;, después construyen el &lt;em&gt;replication controller&lt;/em&gt;, etc&amp;hellip; Sin embargo, revisando la documentación oficial, crear &lt;em&gt;pods&lt;/em&gt; directamente en Kubernetes no tiene mucho sentido.&lt;/p&gt;

&lt;p&gt;En este artículo intento determinar qué objetos son los que deben crearse en un clúster Kubernetes.
&lt;/p&gt;

&lt;h2 id=&#34;pod&#34;&gt;Pod&lt;/h2&gt;

&lt;p&gt;La unidad fundamental de despliegue en Kubernetes es el &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/&#34;&gt;&lt;strong&gt;Pod&lt;/strong&gt;&lt;/a&gt;. Un &lt;em&gt;pod&lt;/em&gt; sería el equivalente a la mínima unidad funcional de la aplicación.&lt;/p&gt;

&lt;p&gt;En general, un &lt;em&gt;pod&lt;/em&gt; contendrá únicamente un contenedor, aunque no tiene que ser así: si tenemos dos contenedores que actúan de forma conjunta, podemos desplegarlos dentro de un solo &lt;em&gt;pod&lt;/em&gt;. Dentro de un &lt;em&gt;pod&lt;/em&gt; todos los contenedores se pueden comunicar entre ellos usando &lt;code&gt;localhost&lt;/code&gt;, por lo que es una manera sencilla de desplegar en Kubernetes aplicaciones que, aunque hayan sido &lt;em&gt;containerizadas&lt;/em&gt;, no puedan modificarse para comunicarse con otras partes de la aplicación usando una IP o un nombre DNS (porque la aplicación espera que el resto de &lt;em&gt;partes&lt;/em&gt; de la aplicación estén en el mismo equipo).&lt;/p&gt;

&lt;p&gt;En este sentido, todos los contenedores dentro de un &lt;em&gt;pod&lt;/em&gt; se podría decir que están instaladas en una mismo equipo (como un &lt;em&gt;stack&lt;/em&gt; LAMP).&lt;/p&gt;

&lt;p&gt;Sin embargo, un &lt;em&gt;pod&lt;/em&gt; es un elemento &lt;strong&gt;no-durable&lt;/strong&gt;, es decir, que puede fallar o ser eliminado en cualquier momento. Por tanto, &lt;strong&gt;no es una buena idea desplegar &lt;em&gt;pods&lt;/em&gt; individuales en Kubernetes&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Como indica la &lt;a href=&#34;https://kubernetes.io/docs/api-reference/v1.6/#pod-v1-core&#34;&gt;documentación para los &lt;em&gt;pods&lt;/em&gt; de la API para la versión 1.6 de Kubernetes&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It is recommended that users create Pods only through a Controller, and not directly.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;replicaset-y-replication-controller&#34;&gt;ReplicaSet y Replication Controller&lt;/h2&gt;

&lt;p&gt;El &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/replicationcontroller/&#34;&gt;&lt;strong&gt;Replication Controller&lt;/strong&gt;&lt;/a&gt; o la versión &lt;em&gt;mejorada&lt;/em&gt;, el &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/&#34;&gt;&lt;strong&gt;ReplicaSet&lt;/strong&gt;&lt;/a&gt; se encarga de mantener un determinado número de réplicas del &lt;em&gt;pod&lt;/em&gt; en el clúster.&lt;/p&gt;

&lt;p&gt;El &lt;em&gt;ReplicaSet&lt;/em&gt; asegura que un determinado número de copias -&lt;strong&gt;réplicas&lt;/strong&gt;- del &lt;em&gt;pod&lt;/em&gt; se encuentran en ejecución en el clúster en todo momento. Por tanto, si alguno de los &lt;em&gt;pods&lt;/em&gt; es eliminado, el &lt;em&gt;ReplicaSet&lt;/em&gt; se encarga de crear un nuevo &lt;em&gt;pod&lt;/em&gt;. Para ello, el &lt;em&gt;ReplicaSet&lt;/em&gt; incluye una plantilla con la que crear nuevos &lt;em&gt;pods&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Así, el &lt;em&gt;ReplicaSet&lt;/em&gt; define el &lt;strong&gt;estado deseado&lt;/strong&gt; de la aplicación: cuántas copias de mi aplicación quiero tener en todo momento en ejecución en el clúster.
Modificando el número de réplicas para el &lt;em&gt;ReplicaSet&lt;/em&gt; podemos &lt;strong&gt;escalar&lt;/strong&gt; (incrementar o reducir) el número de copias en ejecución en función de las necesidades.&lt;/p&gt;

&lt;p&gt;Por tanto, parece que el mejor candidato para ponerse a definir ficheros &lt;code&gt;YAML&lt;/code&gt; y desplegar aplicaciones en el clúster de Kubernetes sería un &lt;em&gt;ReplicaSet&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Si embargo, la &lt;a href=&#34;https://kubernetes.io/docs/api-reference/v1.6/#replicaset-v1beta1-extensions&#34;&gt;documentación oficial&lt;/a&gt; nos ofrece otra opción:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In many cases it is recommended to create a Deployment instead of ReplicaSet.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Es decir, tenemos una opción mejor: el &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/&#34;&gt;&lt;strong&gt;Deployment&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;deployment&#34;&gt;Deployment&lt;/h2&gt;

&lt;p&gt;El &lt;em&gt;Deployment&lt;/em&gt; añade la capacidad de poder actualizar la aplicación definida en un &lt;em&gt;ReplicaSet&lt;/em&gt; sin pérdida de servicio, mediante &lt;strong&gt;actualización continua&lt;/strong&gt; (&lt;em&gt;rolling update&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;Si el estado deseado de la aplicación son tres réplicas de un pod basado en &lt;code&gt;yomismo/app-1.0&lt;/code&gt; y queremos actualizar a &lt;code&gt;yomismo/app-2.0&lt;/code&gt;, el &lt;em&gt;Deployment&lt;/em&gt; se encarga de realizar la transición de la versión 1.0 a la 2.0 de forma que no haya interrupción del servicio. La estrategia de actualización puede definirse manualmente, pero sin entrar en detalles, Kubernetes se encarga de ir eliminado progresivamente las réplicas de la aplicación v1.0 y sustituirlas por las de la v2.0.&lt;/p&gt;

&lt;p&gt;El proceso se hace de forma controlada, por lo que si surgen problemas con la nueva versión de la aplicación, la actualización se detiene y es posible realizar &lt;em&gt;marcha atrás&lt;/em&gt; hacia la versión estable.&lt;/p&gt;

&lt;h2 id=&#34;resumiendo&#34;&gt;Resumiendo&lt;/h2&gt;

&lt;p&gt;Así pues, después de leer la sección de &lt;a href=&#34;https://kubernetes.io/docs/concepts/&#34;&gt;Concepts&lt;/a&gt; de la documentación de Kubernetes, parece que ya tengo claro cuál es el proceso para desplegar aplicaciones en Kubernetes.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;En Docker

&lt;ol&gt;
&lt;li&gt;Crear fichero &lt;code&gt;Dockerfile&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Construir imagen personalizada&lt;/li&gt;
&lt;li&gt;Subir imagen a un &lt;em&gt;Registry&lt;/em&gt; (de momento, DockerHub)&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;En Kubernetes

&lt;ol&gt;
&lt;li&gt;Crear fichero &lt;code&gt;YAML&lt;/code&gt; definiendo el &lt;em&gt;Deployment&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Crear &lt;em&gt;Deployment&lt;/em&gt; en el clúster&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Hay otros objetos específicos que pueden ser más adecuados para tus necesidades:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;DaemonSets&lt;/em&gt; : despliegan una copia de un &lt;em&gt;pod&lt;/em&gt; en cada nodo del clúster. Por ejemplo, un antivirus, o una herramienta de gestión de logs, etc&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Jobs&lt;/em&gt; y &lt;em&gt;CronJobs&lt;/em&gt;: crean &lt;em&gt;pods&lt;/em&gt; hasta asegurar que un número determinado finaliza con éxito, lo que completa el &lt;em&gt;job&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;StatefulSets&lt;/em&gt; : todavía en Beta, asignan una identidad única a los &lt;em&gt;pods&lt;/em&gt;, lo que garantiza que se creen o escalen en un orden determinado.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;siguientes-pasos&#34;&gt;Siguientes pasos&lt;/h2&gt;

&lt;p&gt;Al final de este proceso tendré una aplicación &lt;em&gt;simple&lt;/em&gt; desplegada en el clúster. Con &amp;ldquo;sencilla&amp;rdquo; quiero decir que las diferentes instancias de la aplicación actuan de forma independiente. Un ejemplo sería un servidor web: con el &lt;em&gt;deployment&lt;/em&gt; sería posible escalar la aplicación para dar respuesta a la demanda en todo momento y actualizar el contenido de la web sin interrupciones.&lt;/p&gt;

&lt;p&gt;El siguiente paso es crear una aplicación &lt;em&gt;compleja&lt;/em&gt; en la que tengamos, por ejemplo, un &lt;em&gt;frontend&lt;/em&gt; y un &lt;em&gt;backend&lt;/em&gt;. Para estas situaciones, necesitaremos definir un &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/service/&#34;&gt;&lt;strong&gt;servicio&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>El nodo k3 sigue colgandose por culpa de Flannel</title>
      <link>https://onthedock.github.io/post/170517-el-nodo-k3-sigue-colgandose-por-culpa-de-flannel/</link>
      <pubDate>Wed, 17 May 2017 21:02:21 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170517-el-nodo-k3-sigue-colgandose-por-culpa-de-flannel/</guid>
      <description>&lt;p&gt;En la entrada &lt;a href=&#34;https://onthedock.github.io/post/170506-troubleshooting-kubernetes-ii/&#34;&gt;Troubleshooting Kubernetes (II)&lt;/a&gt; encontré restos de la instalación de &lt;a href=&#34;https://github.com/coreos/flannel&#34;&gt;Flannel&lt;/a&gt; en la Raspberry Pi. Eliminé los &lt;em&gt;pods&lt;/em&gt; que hacían referencia a Flannel y conseguí que el nodo &lt;strong&gt;k2&lt;/strong&gt; no se volviera a colgar.&lt;/p&gt;

&lt;p&gt;Sin embargo, el problema sigue dándose en el nodo &lt;strong&gt;k3&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Revisando el contenido de &lt;code&gt;/var/lib/kubernetes/pods/&lt;/code&gt; he visto que algunos &lt;em&gt;pods&lt;/em&gt; hacían referencia, todavía, a Flannel.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;...
/var/lib/kubelet/pods/3a5e2819-21e5-11e7-bcfd-b827eb650fdb/volumes/kubernetes.io~configmap/wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_flannel-cfg.deleting~470691428.deleting~439642480.deleting~747926470.deleting~067946013.deleting~791070092.deleting~964331938.deleting~717873461.deleting~755129373.deleting~499171027
/var/lib/kubelet/pods/3a5e2819-21e5-11e7-bcfd-b827eb650fdb/volumes/kubernetes.io~configmap/wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_flannel-cfg.deleting~504683568.deleting~184413472.deleting~138413964.deleting~985160408.deleting~943143520.deleting~459558341.deleting~578589077.deleting~501462031.deleting~769373718
/var/lib/kubelet/pods/3a5e2819-21e5-11e7-bcfd-b827eb650fdb/volumes/kubernetes.io~configmap/wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_flannel-cfg.deleting~613861491.deleting~841547526.deleting~012178845.deleting~177797190.deleting~192052322.deleting~958792988.deleting~338401309.deleting~623810479.deleting~369130424
/var/lib/kubelet/pods/3a5e2819-21e5-11e7-bcfd-b827eb650fdb/volumes/kubernetes.io~configmap/wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_flannel-cfg.deleting~470691428.deleting~288881360.deleting~534630955.deleting~520377076.deleting~598159984.deleting~426698803.deleting~142931759.deleting~872800923.deleting~808586860
/var/lib/kubelet/pods/3a5e2819-21e5-11e7-bcfd-b827eb650fdb/volumes/kubernetes.io~configmap/wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_flannel-cfg.deleting~470691428.deleting~439642480.deleting~747926470.deleting~067946013.deleting~791070092.deleting~622848191.deleting~646325460.deleting~868409130.deleting~824166496
/var/lib/kubelet/pods/3a5e2819-21e5-11e7-bcfd-b827eb650fdb/volumes/kubernetes.io~configmap/wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_flannel-cfg.deleting~668636622.deleting~334825066.deleting~737147422.deleting~055159245.deleting~572255670.deleting~485248219.deleting~690855316.deleting~753094008.deleting~457647557
/var/lib/kubelet/pods/3a5e2819-21e5-11e7-bcfd-b827eb650fdb/volumes/kubernetes.io~configmap/wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_flannel-cfg.deleting~756292309.deleting~273222811.deleting~039503494.deleting~182629307.deleting~984614903.deleting~081831640.deleting~628560452.deleting~303652395.deleting~450650534
/var/lib/kubelet/pods/3a5e2819-21e5-11e7-bcfd-b827eb650fdb/volumes/kubernetes.io~configmap/wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_flannel-cfg.deleting~883601122.deleting~535739903.deleting~385002935.deleting~558075878.deleting~174007749.deleting~757820208.deleting~194356513.deleting~813327027.deleting~485662152
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Esta vez he detectado el problema al intentar calcular el espacio usado por esta carpeta, ya que la Raspberry Pi se ha quedado como &amp;ldquo;colgada&amp;rdquo;, aunque al lanzar &lt;em&gt;htop&lt;/em&gt; no se observaba un uso excesivo de CPU.&lt;/p&gt;

&lt;p&gt;Finalmente, he usado el mismo sistema que la otra vez: eliminar todas las subcarpetas de cada uno de los &lt;em&gt;pods&lt;/em&gt; (dejando únicamente los que no se pueden borrar al estar en uso).&lt;/p&gt;

&lt;p&gt;Después de la purga masiva de &lt;code&gt;rm -rf /var/lib/kubelet/pods/&lt;/code&gt; sólo han quedado dos carpetas &lt;em&gt;en uso&lt;/em&gt;; el número corresponde con el número de &lt;em&gt;pods&lt;/em&gt; planificados sobre el nodo &lt;strong&gt;k3&lt;/strong&gt; desde &lt;code&gt;kubectl&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl get pods --all-namespaces -o wide
NAMESPACE     NAME                         READY     STATUS    RESTARTS   AGE       IP             NODE
kube-system   etcd-k1                      1/1       Running   4          36d       192.168.1.11   k1
kube-system   kube-apiserver-k1            1/1       Running   4          36d       192.168.1.11   k1
kube-system   kube-controller-manager-k1   1/1       Running   4          36d       192.168.1.11   k1
kube-system   kube-dns-279829092-1b27r     3/3       Running   12         36d       10.32.0.2      k1
kube-system   kube-proxy-20t3b             1/1       Running   0          25m       192.168.1.13   k3
kube-system   kube-proxy-3dggd             1/1       Running   4          36d       192.168.1.11   k1
kube-system   kube-proxy-5b8k3             1/1       Running   2          12d       192.168.1.12   k2
kube-system   kube-scheduler-k1            1/1       Running   4          36d       192.168.1.11   k1
kube-system   weave-net-6qr0l              2/2       Running   8          36d       192.168.1.11   k1
kube-system   weave-net-mxp2w              2/2       Running   0          25m       192.168.1.13   k3
kube-system   weave-net-tmmdj              2/2       Running   4          12d       192.168.1.12   k2
$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Un reinicio y ¡listo!, problema -espero- resuelto de forma definitiva.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Troubleshooting Kubernetes (II)</title>
      <link>https://onthedock.github.io/post/170506-troubleshooting-kubernetes-ii/</link>
      <pubDate>Sat, 06 May 2017 05:21:09 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170506-troubleshooting-kubernetes-ii/</guid>
      <description>&lt;p&gt;Sigo con el &lt;em&gt;troubleshooting&lt;/em&gt; del &lt;em&gt;cuelgue&lt;/em&gt; de los nodos sobre Raspberry Pi 3 del clúster.&lt;/p&gt;

&lt;p&gt;Ayer estuve &lt;em&gt;haciendo limpieza&lt;/em&gt; siguiendo &lt;em&gt;vagamente&lt;/em&gt; la recomendación de &lt;a href=&#34;https://github.com/kubernetes/kubernetes/issues/43593#issuecomment-288899231&#34;&gt;esta respuesta&lt;/a&gt; en el hilo &lt;a href=&#34;https://github.com/kubernetes/kubernetes/issues/43593#issuecomment-288899231&#34;&gt;Kubernetes memory consumption explosion&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;La solución de &lt;code&gt;RenaudWasTaken&lt;/code&gt; al problema de consumo excesivo de memoria (32GB) fue la realizar limpieza de las carpetas:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/var/run/kubernetes&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/var/lib/kubelet&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/var/lib/etcd&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Antes de empezar a borrar &lt;em&gt;a lo loco&lt;/em&gt;, revisé el contenido de estas carpetas.&lt;/p&gt;

&lt;h2 id=&#34;var-run-kubernetes&#34;&gt;&lt;code&gt;/var/run/kubernetes&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;En &lt;code&gt;/var/run/kubernetes&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ ls -la /var/run/kubernetes/
total 8
drwxr-xr-x  2 root root   80 May  5 18:43 .
drwxr-xr-x 18 root root  600 May  5 18:43 ..
-rw-r--r--  1 root root 1082 May  5 18:43 kubelet.crt
-rw-------  1 root root 1679 May  5 18:43 kubelet.key
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Estos ficheros son certificados, por lo que no parecen implicados en el problema y decido no borrarlos.&lt;/p&gt;

&lt;h2 id=&#34;var-lib-kubelet&#34;&gt;&lt;code&gt;/var/lib/kubelet&lt;/code&gt;&lt;/h2&gt;

&lt;h3 id=&#34;nodo-k2&#34;&gt;Nodo &lt;strong&gt;k2&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Al intentar listar el contenido de la carpeta &lt;code&gt;/var/lib/kubelet/pods&lt;/code&gt;, la Raspberry Pi 3 ha tardado una eternidad (en los primeros intentos he creído que había dejado de responder).&lt;/p&gt;

&lt;p&gt;Finalmente, el resultado del comando ha mostrado una gran cantidad de carpetas dentro de esta carpeta:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ ls -la /var/lib/kubelet/pods
...
drwx------    2 root root    4096 May  4 23:11 wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_flannel-cfg.deleting~443381808.deleting~108562981.deleting~938554959.deleting~743974077.deleting~207819844.deleting~559419937.deleting~142152710.deleting~494766199.deleting~952339001
drwx------    2 root root    4096 May  5 18:02 wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_flannel-cfg.deleting~443381808.deleting~108562981.deleting~938554959.deleting~743974077.deleting~274346355.deleting~274250693.deleting~987962315.deleting~680794233.deleting~917929467
drwx------    2 root root    4096 May  4 23:37 wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_flannel-cfg.deleting~443381808.deleting~108562981.deleting~938554959.deleting~743974077.deleting~274346355.deleting~292131322.deleting~049606881.deleting~105942520.deleting~463246644
drwx------    2 root root    4096 May  4 22:46 wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_flannel-cfg.deleting~443381808.deleting~119491600.deleting~962328406.deleting~220005477.deleting~309794961.deleting~392355244.deleting~378832104.deleting~159122214.deleting~324365539
drwx------    2 root root    4096 Apr 15 20:39 wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_wrapped_flannel-cfg.deleting~443381808.deleting~162549394.deleting~296869341.deleting~353223099.deleting~018715754.deleting~526835026.deleting~320404022.deleting~453576282.deleting~001809150
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Parece como si algo no hubiera funcionado correctamente y hubiera entrado en un bucle, creando carpetas y más carpetas. Además, en el nombre de alguna de estas carpetas aparece &lt;code&gt;..._flannel-cfg...&lt;/code&gt;. Esta ha sido la pista que me ha convencido; al intentar instalar el &lt;em&gt;dashboard&lt;/em&gt; de Kubernetes, tuve problemas precisamente porque no tengo instalado Flannel. Eliminé el &lt;em&gt;pod&lt;/em&gt; y no le di más vueltas.&lt;/p&gt;

&lt;p&gt;Sin embargo, la existencia de estas carpetas parece indicar que la eliminación no fue tan limpia como pensaba y que &lt;em&gt;algo&lt;/em&gt; se quedó atrapado en un bucle.&lt;/p&gt;

&lt;p&gt;He lanzado &lt;code&gt;rm -rf /var/lib/kubelet/pods/&lt;/code&gt; y el comando ha fallado indicando que uno de los &lt;em&gt;pods&lt;/em&gt; estaba en uso. Así que he eliminado poco a poco los &lt;em&gt;pods&lt;/em&gt; hasta que al final:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ ls /var/lib/kubelet/pods/ -la
total 24
drwxr-x--- 4 root root 12288 May  5 18:40 .
drwxr-x--- 4 root root  4096 Apr 15 09:08 ..
drwxr-x--- 5 root root  4096 May  5 18:43 c0323b0f-31bd-11e7-a0ed-b827eb650fdb
drwxr-x--- 5 root root  4096 May  5 18:43 f2da9dfb-31bd-11e7-a0ed-b827eb650fdb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Estos &lt;em&gt;pods&lt;/em&gt;, sean los que sean, están en uso (no tengo nada desplegado en el clúster, así que deben ser &lt;em&gt;de sistema&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;Tras la limpieza, he reiniciado el nodo.&lt;/p&gt;

&lt;h3 id=&#34;nodo-k3&#34;&gt;Nodo &lt;strong&gt;k3&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;El nodo &lt;strong&gt;k3&lt;/strong&gt; no presentaba estas &lt;em&gt;carpetas sospechosas&lt;/em&gt;, pero también he realizado limpieza:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ rm -rf /var/lib/kubelet/pods/
rm: cannot remove ‘/var/lib/kubelet/pods/3a5e2819-21e5-11e7-bcfd-b827eb650fdb/volumes/kubernetes.io~configmap’: Directory not empty
rm: cannot remove ‘/var/lib/kubelet/pods/71290201-31bb-11e7-a0ed-b827eb650fdb/volumes/kubernetes.io~secret/kube-proxy-token-7zk2k’: Device or resource busy
rm: cannot remove ‘/var/lib/kubelet/pods/ef887c6a-31ba-11e7-a0ed-b827eb650fdb/volumes/kubernetes.io~secret/weave-net-token-61scv’: Device or resource busy
$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Igual que en el nodo &lt;strong&gt;k2&lt;/strong&gt;, he reiniciado.&lt;/p&gt;

&lt;h2 id=&#34;resultados&#34;&gt;Resultados&lt;/h2&gt;

&lt;p&gt;Los nodos &lt;strong&gt;k2&lt;/strong&gt; y &lt;strong&gt;k3&lt;/strong&gt; siguen en estado &lt;code&gt;Ready&lt;/code&gt; tras unas siete y ocho horas, que es bastante más de lo que &lt;em&gt;aguantaban&lt;/em&gt; antes.&lt;/p&gt;

&lt;p&gt;He comprobado que en la carpeta &lt;code&gt;/var/lib/kubelet/pods&lt;/code&gt; sólo aparecen dos &lt;em&gt;pods&lt;/em&gt; (en el nodo &lt;strong&gt;k2&lt;/strong&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ ls -la /var/lib/kubelet/pods/
total 24
drwxr-x--- 4 root root 12288 May  5 18:40 .
drwxr-x--- 4 root root  4096 Apr 15 09:08 ..
drwxr-x--- 5 root root  4096 May  5 18:43 c0323b0f-31bd-11e7-a0ed-b827eb650fdb
drwxr-x--- 5 root root  4096 May  5 18:43 f2da9dfb-31bd-11e7-a0ed-b827eb650fdb
$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;En el nodo &lt;strong&gt;k3&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ ls -la /var/lib/kubelet/pods/
total 28
drwxr-x--- 5 root root 12288 May  5 19:44 .
drwxr-x--- 4 root root  4096 Apr 15 14:10 ..
drwxr-x--- 3 root root  4096 May  5 19:33 3a5e2819-21e5-11e7-bcfd-b827eb650fdb
drwxr-x--- 5 root root  4096 May  5 19:37 514d4c93-31c9-11e7-a0ed-b827eb650fdb
drwxr-x--- 5 root root  4096 May  5 19:37 c0b9753a-31c9-11e7-a0ed-b827eb650fdb
$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Más adelante actualizaré el artículo para verificar si los nodos siguen activos y sin problemas.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Instala Weave Net en Kubernetes 1.6</title>
      <link>https://onthedock.github.io/post/170505-instala-weave-net-en-kubernetes-1.6/</link>
      <pubDate>Fri, 05 May 2017 22:14:36 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170505-instala-weave-net-en-kubernetes-1.6/</guid>
      <description>&lt;p&gt;Una de las cosas que más me sorprenden de Kubernetes es que es necesario instalar una &lt;em&gt;capa de red&lt;/em&gt; sobre el clúster.&lt;/p&gt;

&lt;p&gt;En el caso concreto del que he obtenido las &lt;em&gt;capturas de pantalla&lt;/em&gt;, el clúster corre sobre máquinas virtuales con Debian Jessie.
&lt;/p&gt;

&lt;p&gt;La instalación de Weave Net en Kubernetes consiste únicamente en una línea, como explica el artículo: &lt;a href=&#34;https://www.weave.works/weave-net-kubernetes-integration/&#34;&gt;Run Weave Net with Kubernetes in Just One Line&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Antes de instalar la &lt;em&gt;red&lt;/em&gt; en el clúster (de momento, de un solo nodo), &lt;em&gt;kubectl&lt;/em&gt; indica que el estado del nodo es &lt;code&gt;NotReady&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl get nodes
NAME      STATUS     AGE       VERSION
k8s       NotReady   5h        v1.6.1
$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;En la salida del comando tenemos que la versión de Kubernetes es la 1.6.1. Este dato será importante más adelante a la hora de escoger el comando de instalación de Weave Net.&lt;/p&gt;

&lt;p&gt;Si obtenemos la lista de &lt;em&gt;pods&lt;/em&gt;, comprobamos que no tenemos ningún &lt;em&gt;pod de red&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl get pods --all-namespaces
NAMESPACE     NAME                          READY     STATUS    RESTARTS   AGE
kube-system   etcd-k8s                      1/1       Running   0          5h
kube-system   kube-apiserver-k8s            1/1       Running   0          5h
kube-system   kube-controller-manager-k8s   1/1       Running   0          5h
kube-system   kube-dns-3913472980-4nlg9     0/3       Pending   0          5h
kube-system   kube-proxy-l02zn              1/1       Running   0          5h
kube-system   kube-scheduler-k8s            1/1       Running   0          5h
$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Además, los &lt;em&gt;pods&lt;/em&gt; de &lt;em&gt;DNS&lt;/em&gt; &lt;code&gt;kube-dns-*&lt;/code&gt; están en estado &lt;code&gt;Pending&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Siguiendo las instrucciones del artículo de Weave Net, lanzamos el comando de instalación para versiones 1.6 (o superior):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl apply -f https://git.io/weave-kube-1.6
clusterrole &amp;quot;weave-net&amp;quot; created
serviceaccount &amp;quot;weave-net&amp;quot; created
clusterrolebinding &amp;quot;weave-net&amp;quot; created
daemonset &amp;quot;weave-net&amp;quot; created
$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Obtenemos la lista de &lt;em&gt;pods&lt;/em&gt; de nuevo y observamos que se están creando dos nuevos contenedores:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;operador@k8s:~$ kubectl get pods --all-namespaces
NAMESPACE     NAME                          READY     STATUS              RESTARTS   AGE
kube-system   etcd-k8s                      1/1       Running             0          5h
kube-system   kube-apiserver-k8s            1/1       Running             0          5h
kube-system   kube-controller-manager-k8s   1/1       Running             0          5h
kube-system   kube-dns-3913472980-4nlg9     0/3       Pending             0          5h
kube-system   kube-proxy-l02zn              1/1       Running             0          5h
kube-system   kube-scheduler-k8s            1/1       Running             0          5h
kube-system   weave-net-32ptg               0/2       ContainerCreating   0          12s
operador@k8s:~$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;De hecho, se creado el &lt;em&gt;daemonset&lt;/em&gt; &amp;ldquo;weave-net&amp;rdquo;. Un &lt;em&gt;daemonset&lt;/em&gt; es un &lt;em&gt;pod&lt;/em&gt; que se crea en cada uno de los nodos del clúster automáticamente. Kubernetes se encarga de descargar la imagen desde DockerHub y arrancar un contenedor. Los nodos en la red creada por Weave Net forman una red &lt;em&gt;mesh&lt;/em&gt; que se configura automáticamente, de manera que es posible agregar nodos adicionales sin necesidad de cambiar ninguna configuración.&lt;/p&gt;

&lt;p&gt;Pasados unos segundos la creación de los nodos se ha completado:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$  kubectl get pods --all-namespaces
NAMESPACE     NAME                          READY     STATUS         RESTARTS   AGE
kube-system   etcd-k8s                      1/1       Running        0          5h
kube-system   kube-apiserver-k8s            1/1       Running        0          5h
kube-system   kube-controller-manager-k8s   1/1       Running        0          5h
kube-system   kube-dns-3913472980-4nlg9     0/3       ErrImagePull   0          5h
kube-system   kube-proxy-l02zn              1/1       Running        0          5h
kube-system   kube-scheduler-k8s            1/1       Running        0          5h
kube-system   weave-net-32ptg               2/2       Running        0          1m
$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finalmente, verificamos que el primer nodo del clúster ya es operativo:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl get nodes
NAME      STATUS    AGE       VERSION
k8s       Ready     5h        v1.6.1
$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Además, una vez que tenemos la red instalada en el clúster, el &lt;em&gt;pod&lt;/em&gt; &lt;code&gt;kube-dns&lt;/code&gt; comienza la creación de los contenedores (quizás tengas que reiniciar):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl get pods --all-namespaces
NAMESPACE     NAME                          READY     STATUS              RESTARTS   AGE
kube-system   etcd-k8s                      1/1       Running             1          11d
kube-system   kube-apiserver-k8s            1/1       Running             1          11d
kube-system   kube-controller-manager-k8s   1/1       Running             1          11d
kube-system   kube-dns-3913472980-4nlg9     0/3       ContainerCreating   0          11d
kube-system   kube-proxy-l02zn              1/1       Running             1          11d
kube-system   kube-scheduler-k8s            1/1       Running             1          11d
kube-system   weave-net-32ptg               2/2       Running             3          10d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Tras unos segundos, tenemos todos los &lt;em&gt;pods&lt;/em&gt; del clúster funcionales:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl get pods --all-namespaces
NAMESPACE     NAME                          READY     STATUS    RESTARTS   AGE
kube-system   etcd-k8s                      1/1       Running   1          11d
kube-system   kube-apiserver-k8s            1/1       Running   1          11d
kube-system   kube-controller-manager-k8s   1/1       Running   1          11d
kube-system   kube-dns-3913472980-4nlg9     3/3       Running   0          11d
kube-system   kube-proxy-l02zn              1/1       Running   1          11d
kube-system   kube-scheduler-k8s            1/1       Running   1          11d
kube-system   weave-net-32ptg               2/2       Running   3          10d
$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ahora sólo tenemos que añadir nodos &lt;em&gt;worker&lt;/em&gt; y hacer crecer el clúster.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Troubleshooting Kubernetes (I)</title>
      <link>https://onthedock.github.io/post/170430-troubleshooting-kubernetes-i/</link>
      <pubDate>Sun, 30 Apr 2017 15:24:35 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170430-troubleshooting-kubernetes-i/</guid>
      <description>&lt;p&gt;Tras la alegría inicial pensando que la configuración de &lt;em&gt;rsyslog&lt;/em&gt; era la causante de los cuelgues de las dos RPi 3 (&lt;a href=&#34;https://onthedock.github.io/post/170430-k3-colgado-de-nuevo/&#34;&gt;El nodo k3 del clúster colgado de nuevo&lt;/a&gt;), pasadas unas horas los dos nodos &lt;strong&gt;k2&lt;/strong&gt; y &lt;strong&gt;k3&lt;/strong&gt; han dejado de responder de nuevo.&lt;/p&gt;

&lt;p&gt;Así que es el momento de atacar el problema de forma algo más sistemática. Para ello seguiré las instrucciones que proporcina la página de Kubernetes &lt;a href=&#34;https://kubernetes.io/docs/tasks/debug-application-cluster/debug-cluster/&#34;&gt;Troubleshooting Clusters&lt;/a&gt;.
&lt;/p&gt;

&lt;h2 id=&#34;descripción-del-problema&#34;&gt;Descripción del problema&lt;/h2&gt;

&lt;p&gt;Tras unas horas activos y formando parte del clúster, los dos nodos que corren sobre Raspberry Pi 3 dejan de responder y el clúster los muestra como &lt;em&gt;NotReady&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;El clúster está formado por tres Raspberry Pi; el nodo &lt;em&gt;master&lt;/em&gt; es una Raspberry Pi 2 B mientras que los dos nodos &lt;em&gt;worker&lt;/em&gt; son Raspberry Pi 3 B.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl get nodes -o wide
NAME      STATUS     AGE       VERSION   EXTERNAL-IP   OS-IMAGE                        KERNEL-VERSION
k1        Ready      19d       v1.6.2    &amp;lt;none&amp;gt;        Raspbian GNU/Linux 8 (jessie)   4.4.50-hypriotos-v7+
k2        NotReady   15d       v1.6.2    &amp;lt;none&amp;gt;        Raspbian GNU/Linux 8 (jessie)   4.4.50-hypriotos-v7+
k3        NotReady   14d       v1.6.2    &amp;lt;none&amp;gt;        Raspbian GNU/Linux 8 (jessie)   4.4.50-hypriotos-v7+
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ping&#34;&gt;Ping&lt;/h2&gt;

&lt;h3 id=&#34;ping-al-nombre-del-nodo&#34;&gt;Ping al nombre del nodo&lt;/h3&gt;

&lt;p&gt;La prueba más sencilla para ver si los nodos están colgados, es lanzar un ping desde el portátil:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ ping -c5 k2.local
ping: cannot resolve k2.local: Unknown host
$ ping -c5 k3.local
ping: cannot resolve k3.local: Unknown host
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;En esta prueba vemos que ninguno de los nodos responde al nombre que &lt;em&gt;publica&lt;/em&gt; el servicio &lt;a href=&#34;https://en.wikipedia.org/wiki/Avahi_(software)&#34;&gt;Avahi&lt;/a&gt; en el sistema.&lt;/p&gt;

&lt;h3 id=&#34;ping-a-la-ip-del-nodo&#34;&gt;Ping a la IP del nodo&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ ping -c5 192.168.1.12
PING 192.168.1.12 (192.168.1.12): 56 data bytes
64 bytes from 192.168.1.12: icmp_seq=0 ttl=64 time=3.842 ms
64 bytes from 192.168.1.12: icmp_seq=1 ttl=64 time=6.678 ms
64 bytes from 192.168.1.12: icmp_seq=2 ttl=64 time=10.789 ms
64 bytes from 192.168.1.12: icmp_seq=3 ttl=64 time=7.411 ms
64 bytes from 192.168.1.12: icmp_seq=4 ttl=64 time=10.518 ms

--- 192.168.1.12 ping statistics ---
5 packets transmitted, 5 packets received, 0.0% packet loss
round-trip min/avg/max/stddev = 3.842/7.848/10.789/2.584 ms
$ ping -c5 192.168.1.13
PING 192.168.1.13 (192.168.1.13): 56 data bytes
Request timeout for icmp_seq 0
Request timeout for icmp_seq 1
Request timeout for icmp_seq 2
Request timeout for icmp_seq 3

--- 192.168.1.13 ping statistics ---
5 packets transmitted, 0 packets received, 100.0% packet loss
$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;En este caso, el nodo &lt;strong&gt;k2&lt;/strong&gt; sí que responde a ping a la IP, mientras que el nodo &lt;strong&gt;k3&lt;/strong&gt; actúa como si estuviera apagado o con la red deshabilitada.&lt;/p&gt;

&lt;h3 id=&#34;ssh&#34;&gt;SSH&lt;/h3&gt;

&lt;p&gt;Aunque el nodo &lt;strong&gt;k2&lt;/strong&gt; responde a ping, no es posible conectar vía SSH; el intento de conectar no tiene éxito, pero tampoco falla (por &lt;em&gt;timeout&lt;/em&gt;, por ejemplo). He probado a conectar tanto desde el portátil como desde el nodo &lt;strong&gt;k1&lt;/strong&gt;, con el mismo resulado:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ ssh pirate@192.168.1.12

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;kubelet-describe-node&#34;&gt;kubelet describe node&lt;/h2&gt;

&lt;p&gt;Usamos el comando &lt;code&gt;kubelet describe node&lt;/code&gt; para los dos nodos colgados.&lt;/p&gt;

&lt;h3 id=&#34;nodo-k2&#34;&gt;Nodo &lt;strong&gt;k2&lt;/strong&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl describe node k2
Name:			k2
Role:
Labels:			beta.kubernetes.io/arch=arm
			beta.kubernetes.io/os=linux
			kubernetes.io/hostname=k2
Annotations:		node.alpha.kubernetes.io/ttl=0
			volumes.kubernetes.io/controller-managed-attach-detach=true
Taints:			&amp;lt;none&amp;gt;
CreationTimestamp:	Sat, 15 Apr 2017 10:25:31 +0000
Phase:
Conditions:
  Type			Status		LastHeartbeatTime			LastTransitionTime			Reason			Message
  ----			------		-----------------			------------------			------			-------
  OutOfDisk 		Unknown 	Sun, 30 Apr 2017 11:56:26 +0000 	Sun, 30 Apr 2017 11:57:11 +0000 	NodeStatusUnknown 	Kubelet stopped posting node status.
  MemoryPressure 	Unknown 	Sun, 30 Apr 2017 11:56:26 +0000 	Sun, 30 Apr 2017 11:57:11 +0000 	NodeStatusUnknown 	Kubelet stopped posting node status.
  DiskPressure 		Unknown 	Sun, 30 Apr 2017 11:56:26 +0000 	Sun, 30 Apr 2017 11:57:11 +0000 	NodeStatusUnknown 	Kubelet stopped posting node status.
  Ready 		Unknown 	Sun, 30 Apr 2017 11:56:26 +0000 	Sun, 30 Apr 2017 11:57:11 +0000 	NodeStatusUnknown 	Kubelet stopped posting node status.
Addresses:		192.168.1.12,192.168.1.12,k2
Capacity:
 cpu:		4
 memory:	882632Ki
 pods:		110
Allocatable:
 cpu:		4
 memory:	780232Ki
 pods:		110
System Info:
 Machine ID:			9989a26f06984d6dbadc01770f018e3b
 System UUID:			9989a26f06984d6dbadc01770f018e3b
 Boot ID:			84bf8a2b-b83f-445b-a4b3-250dc6e5db40
 Kernel Version:		4.4.50-hypriotos-v7+
 OS Image:			Raspbian GNU/Linux 8 (jessie)
 Operating System:		linux
 Architecture:			arm
 Container Runtime Version:	docker://Unknown
 Kubelet Version:		v1.6.2
 Kube-Proxy Version:		v1.6.2
PodCIDR:			10.244.2.0/24
ExternalID:			k2
Non-terminated Pods:		(2 in total)
  Namespace			Name				CPU Requests	CPU Limits	Memory Requests	Memory Limits
  ---------			----				------------	----------	---------------	-------------
  kube-system			kube-proxy-g580s		0 (0%)		0 (0%)		0 (0%)		0 (0%)
  kube-system			weave-net-kxpk6			20m (0%)	0 (0%)		0 (0%)		0 (0%)
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  CPU Requests	CPU Limits	Memory Requests	Memory Limits
  ------------	----------	---------------	-------------
  20m (0%)	0 (0%)		0 (0%)		0 (0%)
Events:		&amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;nodo-k3&#34;&gt;Nodo &lt;strong&gt;k3&lt;/strong&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl describe node k3
Name:			k3
Role:
Labels:			beta.kubernetes.io/arch=arm
			beta.kubernetes.io/os=linux
			kubernetes.io/hostname=k3
Annotations:		node.alpha.kubernetes.io/ttl=0
			volumes.kubernetes.io/controller-managed-attach-detach=true
Taints:			&amp;lt;none&amp;gt;
CreationTimestamp:	Sat, 15 Apr 2017 14:10:06 +0000
Phase:
Conditions:
  Type			Status		LastHeartbeatTime			LastTransitionTime			Reason			Message
  ----			------		-----------------			------------------			------			-------
  OutOfDisk 		Unknown 	Sun, 30 Apr 2017 10:33:45 +0000 	Sun, 30 Apr 2017 10:34:28 +0000 	NodeStatusUnknown 	Kubelet stopped posting node status.
  MemoryPressure 	Unknown 	Sun, 30 Apr 2017 10:33:45 +0000 	Sun, 30 Apr 2017 10:34:28 +0000 	NodeStatusUnknown 	Kubelet stopped posting node status.
  DiskPressure 		Unknown 	Sun, 30 Apr 2017 10:33:45 +0000 	Sun, 30 Apr 2017 10:34:28 +0000 	NodeStatusUnknown 	Kubelet stopped posting node status.
  Ready 		Unknown 	Sun, 30 Apr 2017 10:33:45 +0000 	Sun, 30 Apr 2017 10:34:28 +0000 	NodeStatusUnknown 	Kubelet stopped posting node status.
Addresses:		192.168.1.13,192.168.1.13,k3
Capacity:
 cpu:		4
 memory:	882632Ki
 pods:		110
Allocatable:
 cpu:		4
 memory:	780232Ki
 pods:		110
System Info:
 Machine ID:			9989a26f06984d6dbadc01770f018e3b
 System UUID:			9989a26f06984d6dbadc01770f018e3b
 Boot ID:			23bf96e4-ec65-489c-be00-d0fa848265f3
 Kernel Version:		4.4.50-hypriotos-v7+
 OS Image:			Raspbian GNU/Linux 8 (jessie)
 Operating System:		linux
 Architecture:			arm
 Container Runtime Version:	docker://Unknown
 Kubelet Version:		v1.6.2
 Kube-Proxy Version:		v1.6.2
PodCIDR:			10.244.3.0/24
ExternalID:			k3
Non-terminated Pods:		(2 in total)
  Namespace			Name				CPU Requests	CPU Limits	Memory Requests	Memory Limits
  ---------			----				------------	----------	---------------	-------------
  kube-system			kube-proxy-bkl4g		0 (0%)		0 (0%)		0 (0%)		0 (0%)
  kube-system			weave-net-3bf40			20m (0%)	0 (0%)		0 (0%)		0 (0%)
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  CPU Requests	CPU Limits	Memory Requests	Memory Limits
  ------------	----------	---------------	-------------
  20m (0%)	0 (0%)		0 (0%)		0 (0%)
Events:		&amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;El nodo &lt;strong&gt;k2&lt;/strong&gt; deja de responder a las 11:56:26, mientras que el &lt;strong&gt;k3&lt;/strong&gt; lo hace a las 10:33:45.&lt;/p&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; Cuando reinicie los dos nodos lo haré a la misma hora, para comprobar si hay diferencias en el tiempo que tarda en dejar de responder cada nodo.&lt;/li&gt;
&lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Actualizar la zona horaria de las Raspberry Pi.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;nodo-k1-ready&#34;&gt;Nodo &lt;strong&gt;k1&lt;/strong&gt; (&lt;code&gt;Ready&lt;/code&gt;)&lt;/h3&gt;

&lt;p&gt;Como referencia, incluimos el mismo comando para el nodo &lt;em&gt;master&lt;/em&gt; &lt;strong&gt;k1&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl describe node k1
Name:			k1
Role:
Labels:			beta.kubernetes.io/arch=arm
			beta.kubernetes.io/os=linux
			kubernetes.io/hostname=k1
			node-role.kubernetes.io/master=
Annotations:		node.alpha.kubernetes.io/ttl=0
			volumes.kubernetes.io/controller-managed-attach-detach=true
Taints:			node-role.kubernetes.io/master:NoSchedule
CreationTimestamp:	Mon, 10 Apr 2017 20:22:32 +0000
Phase:
Conditions:
  Type			Status	LastHeartbeatTime			LastTransitionTime			Reason				Message
  ----			------	-----------------			------------------			------				-------
  OutOfDisk 		False 	Sun, 30 Apr 2017 14:01:10 +0000 	Sun, 30 Apr 2017 06:37:10 +0000 	KubeletHasSufficientDisk 	kubelet has sufficient disk space available
  MemoryPressure 	False 	Sun, 30 Apr 2017 14:01:10 +0000 	Sun, 30 Apr 2017 06:37:10 +0000 	KubeletHasSufficientMemory 	kubelet has sufficient memory available
  DiskPressure 		False 	Sun, 30 Apr 2017 14:01:10 +0000 	Sun, 30 Apr 2017 06:37:10 +0000 	KubeletHasNoDiskPressure 	kubelet has no disk pressure
  Ready 		True 	Sun, 30 Apr 2017 14:01:10 +0000 	Sun, 30 Apr 2017 06:37:20 +0000 	KubeletReady 			kubelet is posting ready status
Addresses:		192.168.1.11,192.168.1.11,k1
Capacity:
 cpu:		4
 memory:	882632Ki
 pods:		110
Allocatable:
 cpu:		4
 memory:	780232Ki
 pods:		110
System Info:
 Machine ID:			9989a26f06984d6dbadc01770f018e3b
 System UUID:			9989a26f06984d6dbadc01770f018e3b
 Boot ID:			55e1fad0-d40c-480b-b039-5586ff728d2c
 Kernel Version:		4.4.50-hypriotos-v7+
 OS Image:			Raspbian GNU/Linux 8 (jessie)
 Operating System:		linux
 Architecture:			arm
 Container Runtime Version:	docker://Unknown
 Kubelet Version:		v1.6.2
 Kube-Proxy Version:		v1.6.2
PodCIDR:			10.244.0.0/24
ExternalID:			k1
Non-terminated Pods:		(7 in total)
  Namespace			Name					CPU Requests	CPU Limits	Memory Requests	Memory Limits
  ---------			----					------------	----------	---------------	-------------
  kube-system			etcd-k1					0 (0%)		0 (0%)		0 (0%)		0 (0%)
  kube-system			kube-apiserver-k1			250m (6%)	0 (0%)		0 (0%)		0 (0%)
  kube-system			kube-controller-manager-k1		200m (5%)	0 (0%)		0 (0%)		0 (0%)
  kube-system			kube-dns-279829092-1b27r		260m (6%)	0 (0%)		110Mi (14%)	170Mi (22%)
  kube-system			kube-proxy-3dggd			0 (0%)		0 (0%)		0 (0%)		0 (0%)
  kube-system			kube-scheduler-k1			100m (2%)	0 (0%)		0 (0%)		0 (0%)
  kube-system			weave-net-6qr0l				20m (0%)	0 (0%)		0 (0%)		0 (0%)
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  CPU Requests	CPU Limits	Memory Requests	Memory Limits
  ------------	----------	---------------	-------------
  830m (20%)	0 (0%)		110Mi (14%)	170Mi (22%)
Events:		&amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;revisando-los-logs-en-el-nodo-master&#34;&gt;Revisando los logs en el nodo &lt;em&gt;master&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;En la guía de &lt;em&gt;Troubleshooting&lt;/em&gt; de Kubernetes, el siguiente paso es revisar los logs. En el caso del nodo &lt;em&gt;master&lt;/em&gt;, los logs relevantes se encuentran en:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/var/log/kube-apiserver.log&lt;/code&gt; - El &lt;em&gt;API Server&lt;/em&gt;, encargado de servir la API&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/var/log/kube-scheduler.log&lt;/code&gt; - El &lt;em&gt;Scheduler&lt;/em&gt;, encargado de las decisiones de planificar los &lt;em&gt;pods&lt;/em&gt; en los nodos&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/var/log/kube-controller-manager.log&lt;/code&gt; - El responsable de gestionar los &lt;em&gt;replication controllers&lt;/em&gt; encargados de mantener el &lt;strong&gt;estado deseado&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Sin embargo, los logs indicados &lt;strong&gt;no existen en la ruta indicada&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ ls /var/log/kube*
ls: cannot access /var/log/kube*: No such file or directory
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Es probable que la documentación no esté actualizada, así que continuaré en cuanto encuentre los logs para poder revisarlos.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Errores sobre Orphaned pods en syslog</title>
      <link>https://onthedock.github.io/post/170430-errores-sobre-orphaned-pods-en-syslog/</link>
      <pubDate>Sun, 30 Apr 2017 12:55:44 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170430-errores-sobre-orphaned-pods-en-syslog/</guid>
      <description>&lt;p&gt;Los nodos &lt;strong&gt;k2&lt;/strong&gt; y &lt;strong&gt;k3&lt;/strong&gt; del clúster dejan de responder pasadas unas horas. La única manera de solucionarlo es reiniciar los nodos. Siguiendo con la revisión de logs, he encontrado que se genera una gran cantidad de entradas en &lt;em&gt;syslog&lt;/em&gt; en referencia a &lt;em&gt;orphaned pods&lt;/em&gt;. Además, el número de estos errores no para de crecer &lt;strong&gt;rápidamente&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ grep &amp;quot;kubelet_volumes.go:114] Orphaned pod&amp;quot; /var/log/syslog | wc -l
118938
$ grep &amp;quot;kubelet_volumes.go:114] Orphaned pod&amp;quot; /var/log/syslog | wc -l
119022
$ grep &amp;quot;kubelet_volumes.go:114] Orphaned pod&amp;quot; /var/log/syslog | wc -l
119170
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Revisando las últimas entradas del log:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-log&#34;&gt;Apr 30 10:57:57 k2 kubelet[3619]: E0430 10:57:57.186318    3619 kubelet_volumes.go:114] Orphaned pod &amp;quot;5064b9d9-2c9e-11e7-a7ae-b827eb650fdb&amp;quot; found, but volume paths are still present on disk.
Apr 30 10:58:01 k2 kubelet[3619]: E0430 10:58:01.759595    3619 kubelet_volumes.go:114] Orphaned pod &amp;quot;6c601e9c-2c9c-11e7-a7ae-b827eb650fdb&amp;quot; found, but volume paths are still present on disk.
Apr 30 10:58:03 k2 kubelet[3619]: E0430 10:58:03.226372    3619 kubelet.go:1549] Unable to mount volumes for pod &amp;quot;weave-net-bs9bs_kube-system(4461d51d-2d93-11e7-a7ae-b827eb650fdb)&amp;quot;: timeout expired waiting for volumes to attach/mount for pod &amp;quot;kube-system&amp;quot;/&amp;quot;weave-net-bs9bs&amp;quot;. list of unattached/unmounted volumes=[weavedb cni-bin cni-bin2 cni-conf dbus lib-modules weave-net-token-61scv]; skipping pod
Apr 30 10:58:03 k2 kubelet[3619]: E0430 10:58:03.238315    3619 pod_workers.go:182] Error syncing pod 4461d51d-2d93-11e7-a7ae-b827eb650fdb (&amp;quot;weave-net-bs9bs_kube-system(4461d51d-2d93-11e7-a7ae-b827eb650fdb)&amp;quot;), skipping: timeout expired waiting for volumes to attach/mount for pod &amp;quot;kube-system&amp;quot;/&amp;quot;weave-net-bs9bs&amp;quot;. list of unattached/unmounted volumes=[weavedb cni-bin cni-bin2 cni-conf dbus lib-modules weave-net-token-61scv]
Apr 30 10:58:05 k2 kubelet[3619]: E0430 10:58:05.830432    3619 kubelet_volumes.go:114] Orphaned pod &amp;quot;bb4d3ea6-2b80-11e7-9388-b827eb650fdb&amp;quot; found, but volume paths are still present on disk.
Apr 30 10:58:08 k2 kubelet[3619]: E0430 10:58:08.435567    3619 kubelet_volumes.go:114] Orphaned pod &amp;quot;cb23be0d-2d7e-11e7-a7ae-b827eb650fdb&amp;quot; found, but volume paths are still present on disk.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Todas estas entradas se encuentran en los logs del nodo &lt;strong&gt;k2&lt;/strong&gt;, donde no hay ningún &lt;em&gt;pod&lt;/em&gt; en ejecución (a parte de los propios de  Kubernetes que el clúster planifica en los diferentes nodos).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Actualización&lt;/strong&gt;: &lt;a href=&#34;https://onthedock.github.io/post/170506-troubleshooting-kubernetes-ii/&#34;&gt;Troubleshooting Kubernetes (II)&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>El nodo k3 del clúster colgado de nuevo</title>
      <link>https://onthedock.github.io/post/170430-k3-colgado-de-nuevo/</link>
      <pubDate>Sun, 30 Apr 2017 11:39:20 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170430-k3-colgado-de-nuevo/</guid>
      <description>&lt;p&gt;En la entrada anterior &lt;a href=&#34;https://onthedock.github.io/post/170430-multiples-mensajes-action-17-suspended/&#34;&gt;Múltiples mensajes &amp;lsquo;action 17 suspended&amp;rsquo; en los logs&lt;/a&gt; comentaba que estaba a la espera de obtener resultados; después de apenas unas horas, ya los tengo: &lt;strong&gt;k3&lt;/strong&gt; se ha vuelto a &lt;em&gt;colgar&lt;/em&gt; mientras que &lt;strong&gt;k2&lt;/strong&gt; no.&lt;/p&gt;

&lt;p&gt;Este resultado parece demostrar que la mala configuración de &lt;em&gt;rsyslog&lt;/em&gt; es la causante de los &lt;em&gt;cuelgues&lt;/em&gt; de las RPi 3 en el clúster de Kubernetes.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Actualización&lt;/strong&gt;: El nodo &lt;strong&gt;k2&lt;/strong&gt; sobre RPi3 sigue colgándose :(&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Actualización II&lt;/strong&gt;: &lt;a href=&#34;https://onthedock.github.io/post/170506-troubleshooting-kubernetes-ii/&#34;&gt;Parece solucionado&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;A modo de recordatorio, los cambios realizados en los dos nodos sobre Raspberry Pi 3 han sido (incluyo el nodo &lt;strong&gt;k1&lt;/strong&gt; con RPi2):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;                                |  k1  |  k2  |  k3  |
                                | RPi2 | RPi3 | RPi3 |
 -------------------------------|------|------|------|
| Modificada conf. de rsyslog   |  No  |  Sí  |  No  |
| Actualización a versión 1.6.2 |  Sí  |  Sí  |  Sí  |
 ----------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hasta ahora, los únicos nodos que se &lt;em&gt;colgaban&lt;/em&gt; eran el &lt;strong&gt;k2&lt;/strong&gt; y el &lt;strong&gt;k3&lt;/strong&gt; (sobre RPi3).&lt;/p&gt;

&lt;p&gt;Al modificar la configuración en de &lt;em&gt;rsyslog&lt;/em&gt; en &lt;strong&gt;k2&lt;/strong&gt; y pasadas unas horas, el único nodo que se sigue colgando es el &lt;strong&gt;k3&lt;/strong&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl get nodes
NAME      STATUS     AGE       VERSION
k1        Ready      19d       v1.6.2
k2        Ready      14d       v1.6.2
k3        NotReady   14d       v1.6.2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Es decir, el fallo a la hora de redirigir los mensajes a &lt;code&gt;/dev/xconsole&lt;/code&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;sólo afectan a las RPi3&lt;/li&gt;
&lt;li&gt;provoca que el sistema se acabe colgando&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Para solucionarlo, como &lt;code&gt;root&lt;/code&gt;:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Abre &lt;code&gt;/etc/rsyslog.conf&lt;/code&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Modifica las últimas líneas (al final del fichero) y coméntalas:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;# The named pipe /dev/xconsole is for the `xconsole&#39; utility.  To use it,
# you must invoke `xconsole&#39; with the `-file&#39; option:
#
#    $ xconsole -file /dev/xconsole [...]
#
# NOTE: adjust the list below, or you&#39;ll go crazy if you have a reasonably
#      busy site..
#
daemon.*;mail.*;\
    news.err;\
    *.=debug;*.=info;\
    *.=notice;*.=warn       |/dev/xconsole
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;deben quedar como:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;#daemon.*;mail.*;\
#        news.err;\
#        *.=debug;*.=info;\
#        *.=notice;*.=warn       |/dev/xconsole
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Podrías comentar la redirección &lt;code&gt;|/dev/xconsole&lt;/code&gt;, pero en este caso el bloque no tendría ninguna funcionalidad, por lo que creo que es &lt;em&gt;más limpio&lt;/em&gt; comentar todo el bloque.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Reinicia el equipo mediante &lt;code&gt;reboot&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>Solución al error de instalación de Kubernetes en Debian Jessie (Missing cgroups: memory)</title>
      <link>https://onthedock.github.io/post/170422-solucion-al-error-missing-cgroups-memory-en-debian-jessie/</link>
      <pubDate>Sat, 22 Apr 2017 07:57:14 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170422-solucion-al-error-missing-cgroups-memory-en-debian-jessie/</guid>
      <description>&lt;p&gt;Al lanzar la inicialización del clúster con &lt;code&gt;kubeadm init&lt;/code&gt; en Debian Jessie, las comprobaciones inciales indican que no se encuentran los &lt;em&gt;cgroups&lt;/em&gt; para la memoria (échale un vistazo al artículo &lt;a href=&#34;https://onthedock.github.io/post/170417-instalacion-de-kubernetes-falla-missing-cgroups-memory/&#34;&gt;La instalación de Kubernetes falla en Debian Jessie (missing cgroups: memory)&lt;/a&gt;). Los &lt;em&gt;cgroups&lt;/em&gt; son una de las piezas fundamentales en las que se basa Docker para &lt;em&gt;aislar&lt;/em&gt; los procesos de los contenedores, por lo que la inicialización del clúster de Kubernetes se detiene.&lt;/p&gt;

&lt;p&gt;La solución es tan sencilla como habilitar los &lt;em&gt;cgroups&lt;/em&gt; durante el arranque.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;En primer lugar, verificamos la versión del &lt;em&gt;kernel&lt;/em&gt; que tenemos instalada:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# uname -a
Linux k8s 3.16.0-4-amd64 #1 SMP Debian 3.16.39-1+deb8u2 (2017-03-07) x86_64 GNU/Linux
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Al lanzar &lt;code&gt;kubeadm init&lt;/code&gt; obtenemos el error:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# kubeadm init
[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
[init] Using Kubernetes version: v1.6.0
[init] Using Authorization mode: RBAC
[preflight] Running pre-flight checks
[preflight] The system verification failed. Printing the output from the verification:
OS: Linux
KERNEL_VERSION: 3.16.0-4-amd64
CONFIG_NAMESPACES: enabled
CONFIG_NET_NS: enabled
CONFIG_PID_NS: enabled
CONFIG_IPC_NS: enabled
CONFIG_UTS_NS: enabled
CONFIG_CGROUPS: enabled
CONFIG_CGROUP_CPUACCT: enabled
CONFIG_CGROUP_DEVICE: enabled
CONFIG_CGROUP_FREEZER: enabled
CONFIG_CGROUP_SCHED: enabled
CONFIG_CPUSETS: enabled
CONFIG_MEMCG: enabled
CONFIG_INET: enabled
CONFIG_EXT4_FS: enabled (as module)
CONFIG_PROC_FS: enabled
CONFIG_NETFILTER_XT_TARGET_REDIRECT: enabled (as module)
CONFIG_NETFILTER_XT_MATCH_COMMENT: enabled (as module)
CONFIG_OVERLAYFS_FS: not set - Required for overlayfs.
CONFIG_AUFS_FS: enabled (as module)
CONFIG_BLK_DEV_DM: enabled (as module)
CGROUPS_CPU: enabled
CGROUPS_CPUACCT: enabled
CGROUPS_CPUSET: enabled
CGROUPS_DEVICES: enabled
CGROUPS_FREEZER: enabled
CGROUPS_MEMORY: missing
DOCKER_VERSION: 17.04.0-ce
[preflight] WARNING: docker version is greater than the most recently validated version. Docker version: 17.04.0-ce. Max validated version: 1.12
[preflight] Some fatal errors occurred:
	missing cgroups: memory
[preflight] If you know what you are doing, you can skip pre-flight checks with `--skip-preflight-checks`
#
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;solución&#34;&gt;Solución&lt;/h2&gt;

&lt;p&gt;La solución la he encontrado en &lt;a href=&#34;https://phabricator.wikimedia.org/T122734&#34;&gt;Enable memory cgroups for default Jessie image&lt;/a&gt;.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Nos convertimos en &lt;em&gt;root&lt;/em&gt;: &lt;code&gt;sudo su -&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Editamos el fichero &lt;code&gt;/etc/default/grup&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;En los parámetros para el arranque de linux (&lt;code&gt;GRUB_CMDLINE_LINUX&lt;/code&gt;) añadimos &lt;code&gt;cgroup_enable=memory&lt;/code&gt;. En mi caso, la línea queda: &lt;code&gt;GRUB_CMDLINE_LINUX_DEFAULT=&amp;quot;quiet cgroup_enable=memory&amp;quot;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Actualizamos &lt;em&gt;grub&lt;/em&gt;: &lt;code&gt;update-grub2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Reiniciamos la máquina: &lt;code&gt;reboot&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;...
[preflight] WARNING: docker version is greater than the most recently validated version. Docker version: 17.04.0-ce. Max validated version: 1.12
[preflight] Some fatal errors occurred:
	missing cgroups: memory
[preflight] If you know what you are doing, you can skip pre-flight checks with `--skip-preflight-checks`
root@k8s:~# nano /etc/default/grub
root@k8s:~# update-grub2
Generating grub configuration file ...
Found linux image: /boot/vmlinuz-3.16.0-4-amd64
Found initrd image: /boot/initrd.img-3.16.0-4-amd64
done
root@k8s:~# reboot
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Al lanzar &lt;code&gt;kubeadm init&lt;/code&gt; de nuevo, el clúster arranca con normalidad:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;root@k8s:~# kubeadm init
[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
[init] Using Kubernetes version: v1.6.0
[init] Using Authorization mode: RBAC
[preflight] Running pre-flight checks
[preflight] WARNING: docker version is greater than the most recently validated version. Docker version: 17.04.0-ce. Max validated version: 1.12
[certificates] Generated CA certificate and key.
[certificates] Generated API server certificate and key.
[certificates] API Server serving cert is signed for DNS names [k8s kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.1.99]
[certificates] Generated API server kubelet client certificate and key.
[certificates] Generated service account token signing key and public key.
[certificates] Generated front-proxy CA certificate and key.
[certificates] Generated front-proxy client certificate and key.
[certificates] Valid certificates and keys now exist in &amp;quot;/etc/kubernetes/pki&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;/etc/kubernetes/scheduler.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;/etc/kubernetes/admin.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;/etc/kubernetes/kubelet.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;/etc/kubernetes/controller-manager.conf&amp;quot;
[apiclient] Created API client, waiting for the control plane to become ready
[apiclient] All control plane components are healthy after 39.363656 seconds
[apiclient] Waiting for at least one node to register
[apiclient] First node has registered after 1.518215 seconds
[token] Using token: fe9e91.7142118e712eb019
[apiconfig] Created RBAC rules
[addons] Created essential addon: kube-proxy
[addons] Created essential addon: kube-dns

Your Kubernetes master has initialized successfully!

To start using your cluster, you need to run (as a regular user):

  sudo cp /etc/kubernetes/admin.conf $HOME/
  sudo chown $(id -u):$(id -g) $HOME/admin.conf
  export KUBECONFIG=$HOME/admin.conf

You should now deploy a pod network to the cluster.
Run &amp;quot;kubectl apply -f [podnetwork].yaml&amp;quot; with one of the options listed at:
  http://kubernetes.io/docs/admin/addons/

You can now join any number of machines by running the following on each node
as root:

  kubeadm join --token fe9e91.7142118e712eb019 192.168.1.99:6443

root@k8s:~#
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Cómo agregar un nodo a un cluster Kubernetes</title>
      <link>https://onthedock.github.io/post/170417-como-agregar-un-nodo-a-un-cluster-kubernetes/</link>
      <pubDate>Sat, 15 Apr 2017 16:27:30 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170417-como-agregar-un-nodo-a-un-cluster-kubernetes/</guid>
      <description>&lt;p&gt;Después de realizar la instalación del nodo &lt;em&gt;master&lt;/em&gt; del clúster Kubernetes, el siguiente paso es agregar nodos adicionales al clúster. Es en estos nodos donde se van a planificar los &lt;em&gt;pods&lt;/em&gt; que realizan las funciones &lt;em&gt;productivas&lt;/em&gt; del clúster (en el nodo &lt;em&gt;master&lt;/em&gt; sólo realiza tareas de gestión del clúster).&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;cómo-agregar-un-nodo-a-un-cluster-kubernetes&#34;&gt;Cómo agregar un nodo a un cluster Kubernetes&lt;/h1&gt;

&lt;p&gt;En el nodo que vamos a añadir tenemos instalador HypriotOS (una distribución basada en Debian creada específicamente para ejecutar Docker en la Raspberry Pi).&lt;/p&gt;

&lt;p&gt;Hypriot OS tiene instalado Docker &lt;em&gt;de fábrica&lt;/em&gt; así que comprobamos la versión instalada:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ docker version
Client:
 Version:      17.04.0-ce
 API version:  1.28
 Go version:   go1.7.5
 Git commit:   4845c56
 Built:        Mon Apr  3 18:22:23 2017
 OS/Arch:      linux/arm

Server:
 Version:      17.04.0-ce
 API version:  1.28 (minimum version 1.12)
 Go version:   go1.7.5
 Git commit:   4845c56
 Built:        Mon Apr  3 18:22:23 2017
 OS/Arch:      linux/arm
 Experimental: false
$
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;tareas-previas&#34;&gt;Tareas previas&lt;/h2&gt;

&lt;p&gt;La instalación de HypriotOS define como nombre del &lt;em&gt;host&lt;/em&gt; &lt;code&gt;black-pearl&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Lo primero que haremos será cambiar el nombre del &lt;em&gt;host&lt;/em&gt;. Para ello modificamos el fichero &lt;code&gt;/boot/device-init.yaml&lt;/code&gt; especificando el nombre elegido para el nuevo nodo. En mi caso, &lt;code&gt;k2&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ sudo nano /boot/device-init.yaml

# hostname for your HypriotOS device
hostname: k2

# optional wireless network settings
wifi:
  interfaces:
#     wlan0:
#       ssid: &amp;quot;MyNetwork&amp;quot;
#       password: &amp;quot;secret_password&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para que los cambios tenga efecto, es necesario reiniciar el equipo. Antes, sin embargo, vamos a establecer una IP fija.&lt;/p&gt;

&lt;p&gt;Creamos una copia del fichero &lt;code&gt;/etc/network/interfaces.d/eth0&lt;/code&gt; antes de editarlo:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ sudo cp /etc/network/interfaces.d/eth0 /etc/network/interfaces.d/eth0.original
$ sudo nano /etc/network/interfaces.d/eth0
allow-hotplug eth0
iface eth0 inet static
  address 192.168.1.12
  gateway 192.168.1.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Una vez realizadas las modificaciones del &lt;em&gt;hostname&lt;/em&gt; y de la dirección IP, reiniciamos el &lt;em&gt;host&lt;/em&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ sudo reboot
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;instalación-de-kubernetes-kubeadm-kubectl-y-kubelet&#34;&gt;Instalación de Kubernetes (&lt;code&gt;kubeadm&lt;/code&gt;,  &lt;code&gt;kubectl&lt;/code&gt; y &lt;code&gt;kubelet&lt;/code&gt;)&lt;/h2&gt;

&lt;p&gt;Seguimos las instrucciones de la página oficial de Kubernetes: &lt;a href=&#34;https://kubernetes.io/docs/getting-started-guides/kubeadm/&#34;&gt;Installing Kubernetes on Linux with kubeadm&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Nos conectamos a la máquina vía &lt;em&gt;SSH&lt;/em&gt; y nos convertimos en &lt;code&gt;root&lt;/code&gt; mediante &lt;code&gt;sudo su -&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ apt-get update &amp;amp;&amp;amp; apt-get install -y apt-transport-https
...
apt-transport-https is already the newest version.0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;El siguiente paso es obtener la clave GPG:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Añadimos el repositorio de Kubernetes y actualizamos la lista de paquetes:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ cat &amp;lt;&amp;lt;EOF &amp;gt;/etc/apt/sources.list.d/kubernetes.list
deb http://apt.kubernetes.io/ kubernetes-xenial main
EOF
$ apt-get update
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Verificamos que tenemos Docker instalado (en nuestro caso, &lt;code&gt;docker-engine&lt;/code&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ apt-get install -y docker-engine
...
docker-engine is already the newest version.0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ahora es el momento de lanzar la instalación de los diferentes componentes de Kubernets:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ apt-get install -y kubelet kubeadm kubectl kubernetes-cni
...
The following extra packages will be installed:  ebtables socatThe following NEW packages will be installed:  ebtables kubeadm kubectl kubelet kubernetes-cni socat0 upgraded, 6 newly installed, 0 to remove and 0 not upgraded.Need to get 37.1 MB of archives.After this operation, 266 MB of additional disk space will be used.0% [Working]
...
Setting up kubernetes-cni (0.5.1-00) ...
Setting up socat (1.7.2.4-2) ...
Setting up kubelet (1.6.1-00) ...
Setting up kubectl (1.6.1-00) ...
Setting up kubeadm (1.6.1-00) ...
Processing triggers for systemd (215-17+deb8u6) ...
$
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;agregar-nodo-al-clúster&#34;&gt;Agregar nodo al clúster&lt;/h2&gt;

&lt;p&gt;Para añadir el &lt;em&gt;host&lt;/em&gt; como un nodo adicional del clúster de Kubernetes, usaremos el comando &lt;code&gt;kubeadm join --token {token} {IP-nodo-master}:puerto&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;El comando &lt;code&gt;kubeadm&lt;/code&gt; genera el token al inicializar el clúster, pero si no lo tenemos apuntado, podemos obtenerlo conectando al nodo &lt;em&gt;master&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ ssh pirate@k1.local
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para obtener el &lt;em&gt;token&lt;/em&gt;, nos convertimos en el usuario &lt;code&gt;root&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ sudo su -
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A continuación, obtenemos la lista de &lt;em&gt;tokens&lt;/em&gt; generados en el clúster:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubeadm token list
TOKEN                     TTL         EXPIRES   USAGES                 DESCRIPTION
5e6517.b9e07...293ff612   &amp;lt;forever&amp;gt;   &amp;lt;never&amp;gt;   authentication,signing   The default bootstrap token generated by &#39;kubeadm init&#39;.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Copiamos el &lt;em&gt;token&lt;/em&gt; y cerramos la conexión con el nodo &lt;em&gt;master&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;En el &lt;em&gt;host&lt;/em&gt; que vamos a unir como nodo al clúster, ejecutamos (como &lt;code&gt;root&lt;/code&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubeadm join --token=5e6517.b9e07...293ff612 192.168.1.11:6443
[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
[preflight] Running pre-flight checks
[preflight] WARNING: docker version is greater than the most recently validated version. Docker version: 17.04.0-ce. Max validated version: 1.12
[discovery] Trying to connect to API Server &amp;quot;192.168.1.11:6443&amp;quot;
[discovery] Created cluster-info discovery client, requesting info from &amp;quot;https://192.168.1.11:6443&amp;quot;
[discovery] Cluster info signature and contents are valid, will use API Server &amp;quot;https://192.168.1.11:6443&amp;quot;
[discovery] Successfully established connection with API Server &amp;quot;192.168.1.11:6443&amp;quot;
[bootstrap] Detected server version: v1.6.0
[bootstrap] The server supports the Certificates API (certificates.k8s.io/v1beta1)
[csr] Created API client to obtain unique certificate for this node, generating keys and certificate signing request
[csr] Received signed certificate from the API server, generating KubeConfig...
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;/etc/kubernetes/kubelet.conf&amp;quot;
Node join complete:
   * Certificate signing request sent to master and response  received.
   * Kubelet informed of new secure connection details.

   Run &#39;kubectl get nodes&#39; on the master to see this machine join.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;verificación&#34;&gt;Verificación&lt;/h2&gt;

&lt;p&gt;Para comprobar que el nodo &lt;code&gt;k2&lt;/code&gt; se ha añadido correctamente al clúster, nos conectamos al nodo &lt;em&gt;master&lt;/em&gt; y obtenemos la lista de nodos:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl get nodes
NAME       STATUS     AGE       VERSION
k1         Ready      4d        v1.6.1
k2.local         NotReady   40s       v1.6.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;El nodo &lt;code&gt;k2&lt;/code&gt; del clúster aparece como &lt;code&gt;NotReady&lt;/code&gt;. Esta situación debe ser temporal. Tras unos instantes, al ejecutar de nuevo el comando, el &lt;em&gt;status&lt;/em&gt; del nuevo nodo debería haber cambiado y mostrarse como &lt;code&gt;Ready&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl get nodes
NAME       STATUS    AGE       VERSION
k1         Ready     4d        v1.6.1
k2.local   Ready     1m        v1.6.1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;cambio-de-nombre-del-nodo&#34;&gt;Cambio de nombre del nodo&lt;/h2&gt;

&lt;p&gt;Incialmente he añadido el nodo al cúster como &lt;code&gt;k2.local&lt;/code&gt;, sin darme cuenta que el sufijo &lt;code&gt;.local&lt;/code&gt; lo añade el &lt;em&gt;daemon&lt;/em&gt; Avahi al publicar el nombre del &lt;em&gt;host&lt;/em&gt; en la red local.&lt;/p&gt;

&lt;p&gt;He modificado el nombre del nodo en el fichero &lt;code&gt;/boot/device-init.yaml&lt;/code&gt; y he reiniciado el nodo, pero a nivel del clúster, el nodo &lt;code&gt;k2.local&lt;/code&gt; sigue formando parte del mismo. Por eso aparece como &lt;code&gt;NotReady&lt;/code&gt; al ejecutar &lt;code&gt;get nodes&lt;/code&gt;. El &lt;em&gt;nuevo&lt;/em&gt;  nodo &lt;code&gt;k2&lt;/code&gt; sí que aparece en al ejecutar el comando &lt;code&gt;get nodes&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl get nodes
NAME       STATUS     AGE       VERSION
k1         Ready      4d        v1.6.1
k2         Ready      37m       v1.6.1
k2.local   NotReady   1h        v1.6.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para evitar confusiones, lo más conveniente es eliminar el nodo del clúster mediante &lt;code&gt;kubectl delete node&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl delete node k2.local
node &amp;quot;k2.local&amp;quot; deleted

$ kubectl get nodes
NAME      STATUS    AGE       VERSION
k1        Ready     4d        v1.6.1
k2        Ready     45m       v1.6.1
$
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Error: The connection to the server localhost:8080 was refused</title>
      <link>https://onthedock.github.io/post/170414-error_the-connection-to-the-server-was-refused/</link>
      <pubDate>Fri, 14 Apr 2017 18:10:34 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170414-error_the-connection-to-the-server-was-refused/</guid>
      <description>&lt;p&gt;Después de &lt;a href=&#34;https://onthedock.github.io/post/170410-k8s-en-rpi-teaser/&#34;&gt;conseguir arrancar Kubernetes tras la instalación&lt;/a&gt;, al intentar ejecutar comandos vía &lt;code&gt;kubectl&lt;/code&gt; obtengo el mensaje de error &lt;code&gt;The connection to the server localhost:8080 was refused - did you specify the right host or port?&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;A continuación explico cómo solucionar el error y evitar que vuelva a mostrarse.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;En la guía oficial para instalar Kubernetes en Linux con &lt;code&gt;kubeadm&lt;/code&gt; &lt;a href=&#34;https://kubernetes.io/docs/getting-started-guides/kubeadm/&#34;&gt;Installing Kubernetes on Linux with kubeadm&lt;/a&gt;, en la salida del comando &lt;code&gt;kubeadm init&lt;/code&gt; en el punto &lt;em&gt;(&lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;4&lt;/sub&gt;) - Initializing your master&lt;/em&gt;, se muestra:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Your Kubernetes master has initialized successfully!

To start using your cluster, you need to run (as a regular &amp;gt;user):

 sudo cp /etc/kubernetes/admin.conf $HOME/
 sudo chown $(id -u):$(id -g) $HOME/admin.conf
 export KUBECONFIG=$HOME/admin.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;El problema es que la &lt;em&gt;exportación&lt;/em&gt; de la variable de entorno realizada mediante &lt;code&gt;export KUBECONFIG=$HOME/admin.conf&lt;/code&gt; &lt;strong&gt;se pierde en cuanto se cierra la sesión&lt;/strong&gt;.
Por tanto, cuando reconectamos más tarde, la variable &lt;code&gt;KUBECONFIG&lt;/code&gt; está vacía y el comando &lt;code&gt;kubectl&lt;/code&gt; intenta conectar con &lt;code&gt;localhost:8080&lt;/code&gt;. Como el API server no está escuchando en esta IP y puerto, lo que obtenemos el mensaje de error:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;The connection to the server localhost:8080 was refused - did you specify the right host or port?
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Si miramos el contenido del fichero &lt;code&gt;$HOME/admin.conf&lt;/code&gt; mediante &lt;code&gt;cat $HOME/admin.conf&lt;/code&gt; encontramos una línea que identifica el servidor: &lt;code&gt;server: https://192.168.1.11:6443&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Parece que lo único que tenemos que hacer es especificar el servidor como parámetro para &lt;code&gt;kubectl&lt;/code&gt;, pero&amp;hellip;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl get nodes --server=https://192.168.1.11:6443
Please enter Username: pirate
Please enter Password: ********
  Unable to connect to the server: x509: certificate signed by unknown authority
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Si usamos el usuario &lt;code&gt;root&lt;/code&gt;, el resultado es el mismo.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Observando el contenido del fichero &lt;code&gt;admin.conf&lt;/code&gt; vemos que para el parámetro &lt;code&gt;user&lt;/code&gt; se especifican certificados (mediante &lt;code&gt;client-certificate-data&lt;/code&gt; y &lt;code&gt;client-key-data&lt;/code&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;...
users:
- name: kubernetes-admin
  user:
    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM4akNDQ...
    client-key-data:   LS0tLS1CRUdJTiBSU0EgUFJJVkFURSBLQVdLN3JjWDIKY2DIKY2t1c...
$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Así que no podemos autenticarnos en el API Server con los usuarios del sistema y tenemos que usar los certificados en el fichero &lt;code&gt;admin.conf&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Esto nos lleva de nuevo a la variable &lt;code&gt;KUBECONFIG&lt;/code&gt;. Si lanzamos el comando &lt;code&gt;export KUBECONFIG...&lt;/code&gt;, los comandos funcionarán durante la sesión en curso, pero tendremos que lanzar el comando &lt;code&gt;export&lt;/code&gt; en cada nueva sesión:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ export KUBECONFIG=$HOME/admin.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;La solución para que la variable se establezca automáticamente en cada inicio de sesión es añadiéndo el valor en el fichero &lt;code&gt;$HOME/.bashrc&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ nano $HOME/.bashrc
export KUBECONFIG=$HOME/admin.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para verificar que funciona como debe, cierra sesión y vuelve a iniciarla.&lt;/p&gt;

&lt;p&gt;Comprueba que puedes lanzar comandos sin problemas:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl get nodes
NAME      STATUS    AGE       VERSION
k1        Ready     3d        v1.6.1
$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;¡Problema solucionado!&lt;/p&gt;

&lt;p&gt;Otra solución alternativa, si no quieres modificar el fichero &lt;code&gt;$HOME/admin.conf&lt;/code&gt; es pasar la ubicación del fichero como parámetro a &lt;code&gt;kubectl&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl get nodes
The connection to the server localhost:8080 was refused - did you specify the right host or port?
$ kubectl --kubeconfig ./admin.conf get nodes
NAME      STATUS    AGE       VERSION
k1        Ready     3d        v1.6.1
$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Puedes usar también este método para conectar, por ejemplo, desde otro equipo al nodo master del clúster (debes copiar primero el fichero &lt;code&gt;admin.conf&lt;/code&gt; a tu equipo, desde su ubicación original &lt;code&gt;/etc/kubernetes/admin.conf&lt;/code&gt; o desde la carpeta &lt;code&gt;$HOME&lt;/code&gt; del usuario, si lo has copiado):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ scp pirate@k1.local:/home/pirate/admin.conf .
kubectl --kubeconfig ./admin.conf get nodes
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Kubernetes en la Raspberry Pi (teaser)</title>
      <link>https://onthedock.github.io/post/170410-k8s-en-rpi-teaser/</link>
      <pubDate>Mon, 10 Apr 2017 22:45:28 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170410-k8s-en-rpi-teaser/</guid>
      <description>&lt;figure&gt;
  &lt;amp-img src=&#34;https://onthedock.github.io/images/170410/itsalive.jpg&#34; alt=&#34;Kubernetes en la Raspberry Pi (teaser) images/170410/itsalive.jpg&#34; width=400 height=292 layout=&#34;responsive&#34;&gt;&lt;/amp-img&gt;
  
&lt;/figure&gt;


&lt;p&gt;&lt;/p&gt;

&lt;p&gt;&lt;figure&gt;
  &lt;amp-img src=&#34;https://onthedock.github.io/images/170410/k8s-en-rpi.png&#34; alt=&#34;Kubernetes en la Raspberry Pi (teaser) images/170410/k8s-en-rpi.png&#34; width=640 height=259 layout=&#34;responsive&#34;&gt;&lt;/amp-img&gt;
  
  &lt;figcaption&gt;
    
    Todos los componentes necesarios en Running
    
  &lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Acciones previas a la instalación de Kubernetes en Raspberry Pi</title>
      <link>https://onthedock.github.io/post/170409-acciones-previas-instalacion-rpi/</link>
      <pubDate>Sun, 09 Apr 2017 21:34:16 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170409-acciones-previas-instalacion-rpi/</guid>
      <description>&lt;p&gt;Uno de los objetivos motivadores de la existencia de este blog es instalar un clúster de Kubernetes sobre Raspberry Pi. Este artículo se centra en las tareas previas a la instalación en sí.&lt;/p&gt;

&lt;p&gt;Kubernetes requiere una instalación previa de Docker, una tarea simplificada gracias a HypriotOS, la &lt;em&gt;distro&lt;/em&gt; creada específicamente con este fin.&lt;/p&gt;

&lt;p&gt;El siguiente paso, la instalación de Kubernetes en la Raspberry será objeto de otra(s) entrada(s). Pero sin duda esta tarea sería mucho más complicada sin las contribuciones del joven finlandés &lt;a href=&#34;https://www.cncf.io/blog/2016/11/29/diversity-scholarship-series-programming-journey-becoming-kubernetes-maintainer/&#34;&gt;Lucas Käldström&lt;/a&gt; y su proyecto -ahora integrado la rama principal- &lt;a href=&#34;https://github.com/luxas/kubernetes-on-arm&#34;&gt;Kubernetes on ARM&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Descarga la imagen de &lt;a href=&#34;https://blog.hypriot.com/downloads/&#34;&gt;HypriotOS&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Traspásala a una tarjeta microSD usando, por ejemplo, &lt;a href=&#34;https://etcher.io/&#34;&gt;Etcher&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Inserta la tarjeta microsSD en la Raspberry Pi y arranca la RPi.&lt;/li&gt;
&lt;li&gt;Comprueba que ha arrancado correctamente haciendo ping a &lt;code&gt;black-pearl.local&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Accede a la RPi mediante &lt;code&gt;ssh pirate@black-pearl.local&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Acepta el mensaje de seguridad (es la primera vez que conectas al equipo)&lt;/li&gt;
&lt;li&gt;Edita el fichero &lt;code&gt;/boot/device-init.yaml&lt;/code&gt; para modificar el nombre de la RPi. En mi caso, he cambiado el nombre a &lt;code&gt;k1&lt;/code&gt;: &lt;code&gt;hostname: k1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Crea un backup del fichero de configuración de la tarjeta de red: &lt;code&gt;sudo cp /etc/network/interfaces.d/eth0 /etc/network/interfaces.d/eth0.original&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Edita el fichero &lt;code&gt;/etc/network/interfaces.d/eth0&lt;/code&gt; para establecer una IP estática para la RPi:&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;  allow-hotplug eth0
  iface eth0 inet static
	address 192.168.1.11
	gateway 192.168.1.1
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Reinicia la RPi para que los cambios sean efectivos: &lt;code&gt;sudo reboot&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Comprueba que la RPi responde a ping con el nuevo nombre: &lt;code&gt;ping k1.local&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Accede a la RPi mediante &lt;code&gt;ssh pirate@k1.local&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Actualiza la RPi: &lt;code&gt;sudo apt-get update &amp;amp;&amp;amp; sudo apt-get upgrade -y&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Verifica la versión de Docker instalada: &lt;code&gt;$ docker version&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>